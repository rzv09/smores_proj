{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.torch import DeepAREstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../3OEC_current_flow.csv')\n",
    "\n",
    "df[\"O2_avg\"] = df[[\"O2_S1\", \"O2_S2\", \"O2_S3\"]].mean(axis=1)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_time_11 = datetime(2017, 7, 11, 14, 0, 0)\n",
    "end_time_11 = datetime(2017, 7, 12, 8, 0, 0)\n",
    "\n",
    "start_time_13 = datetime(2017, 7, 13, 11, 0, 0)\n",
    "end_time_13 = datetime(2017, 7, 14, 6, 0, 0)\n",
    "\n",
    "start_time_15 = datetime(2017, 7, 15, 10, 0, 0)\n",
    "end_time_15 = datetime(2017, 7, 16, 6, 0, 0)\n",
    "\n",
    "start_time_16 = datetime(2017, 7, 16, 16, 0, 0)\n",
    "end_time_16 = datetime(2017, 7, 17, 6, 0, 0)\n",
    "\n",
    "deployments = {\n",
    "    \"3oec_2017_7_11_12\": {\"start\": start_time_11, \"end\": end_time_11},\n",
    "    \"3oec_2017_7_13_14\": {\"start\": start_time_13, \"end\": end_time_13},\n",
    "    \"3oec_2017_7_15_16\": {\"start\": start_time_15, \"end\": end_time_15},\n",
    "    \"3oec_2017_7_16_17\": {\"start\": start_time_16, \"end\": end_time_16}\n",
    "}\n",
    "\n",
    "date_ranges = []\n",
    "\n",
    "for deployment_name, deployment_info in deployments.items():\n",
    "    start_time = deployment_info[\"start\"]\n",
    "    end_time = deployment_info[\"end\"]\n",
    "    if deployment_name == \"3oec_2017_7_13_14\":\n",
    "        start_time -= timedelta(seconds=0.125)\n",
    "    print(start_time)\n",
    "\n",
    "    # Calculate total seconds and number of measurements\n",
    "    total_seconds = (end_time - start_time).total_seconds() + 0.125\n",
    "    num_measurements = int(total_seconds * 8)\n",
    "\n",
    "    # Create DatetimeIndex for the deployment\n",
    "    date_range = pd.date_range(start=start_time, periods=num_measurements, freq=f'{1000/8}ms')\n",
    "    print(date_range[0], date_range[-1])\n",
    "    print(len(date_range))\n",
    "    date_ranges.append(pd.Series(date_range))\n",
    "\n",
    "# Concatenate all DatetimeIndexes\n",
    "complete_index = pd.concat(date_ranges)\n",
    "\n",
    "# Set the complete index to your DataFrame\n",
    "df.index = complete_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop deployment column and resample\n",
    "df_resampled = df.drop(columns=['deployment', 't', 't_increase', 'Vx', 'Vy', 'Vz', 'P', 'O2_S1', 'O2_S2', 'O2_S3']).resample('5min').mean()\n",
    "first_piece = df_resampled[\"2017-07-11\":\"2017-07-12 06:00:00\"]\n",
    "second_piece = df_resampled[\"2017-07-13 12:00:00\":\"2017-07-14 06:00:00\"]\n",
    "third_piece = df_resampled[\"2017-07-15 12:00:00\":\"2017-07-16 6:00:00\"]\n",
    "fourth_piece = df_resampled[\"2017-07-16 16:00:00\":\"2017-07-17\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_piece['timestamp'] = first_piece.index\n",
    "first_piece\n",
    "second_piece['timestamp'] = second_piece.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.util import to_pandas\n",
    "freq=\"5min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap first_piece and second_piece separately\n",
    "train_full = PandasDataset(\n",
    "    dataframes=first_piece,\n",
    "    freq=freq,\n",
    "    target=\"O2_avg\",\n",
    "    timestamp=\"timestamp\",\n",
    ")\n",
    "\n",
    "test_full = PandasDataset(\n",
    "    dataframes=second_piece,\n",
    "    freq=freq,\n",
    "    target=\"O2_avg\",\n",
    "    timestamp=\"timestamp\",\n",
    ")\n",
    "\n",
    "# now: create a \"test template\" *from the test_full dataset*\n",
    "# choose a split point inside second_piece where you want forecasting to start.\n",
    "# usually that's just the start of second_piece if you want to forecast all of it.\n",
    "# So we split right at the first timestamp of second_piece.\n",
    "\n",
    "prediction_length = 6  # 6 * 5min = 30 minutes\n",
    "test_start_period = pd.Period(\n",
    "    second_piece[\"timestamp\"].iloc[0],\n",
    "    freq=freq\n",
    ")\n",
    "\n",
    "_, test_template = split(\n",
    "    test_full,\n",
    "    date=test_start_period\n",
    ")\n",
    "\n",
    "# NOW we can call generate_instances on test_template\n",
    "test_pairs = test_template.generate_instances(\n",
    "    prediction_length=prediction_length,\n",
    "    windows=10,\n",
    ")\n",
    "\n",
    "############################################\n",
    "# 2. Helper: PeriodIndex -> DatetimeIndex\n",
    "############################################\n",
    "def _to_datetime_index(s_or_df):\n",
    "    obj = s_or_df.copy()\n",
    "    if isinstance(obj.index, pd.PeriodIndex):\n",
    "        obj.index = obj.index.to_timestamp()  # cast PeriodIndex -> DatetimeIndex\n",
    "    return obj\n",
    "\n",
    "############################################\n",
    "# 3. Shading helper for visualization\n",
    "############################################\n",
    "def highlight_entry(entry, color, label=None):\n",
    "    \"\"\"\n",
    "    entry[\"start\"] is a pandas.Period\n",
    "    entry[\"target\"] is array-like of values\n",
    "    We shade from the first timestamp covered by this entry\n",
    "    to the timestamp immediately after the last step.\n",
    "    \"\"\"\n",
    "    start_period = entry[\"start\"]\n",
    "    n = int(len(entry[\"target\"]))\n",
    "    left = start_period.to_timestamp()\n",
    "    right = (start_period + n).to_timestamp()\n",
    "    plt.axvspan(left, right, facecolor=color, alpha=0.2, label=label)\n",
    "\n",
    "############################################\n",
    "# 4. Make windows from the test dataset\n",
    "############################################\n",
    "# You said: windows of length 30 min.\n",
    "# Your freq is 5min, so 30 min = 6 steps.\n",
    "\n",
    "\n",
    "############################################\n",
    "# 5. Plotting\n",
    "############################################\n",
    "def plot_train_and_test_windows(train_dataset, test_dataset, test_pairs):\n",
    "    # Plot training dataset coverage (red)\n",
    "    for original_entry, train_entry in zip(train_dataset, train_dataset):\n",
    "        s = _to_datetime_index(to_pandas(original_entry))\n",
    "        ax = s.plot()\n",
    "        highlight_entry(train_entry, \"red\", label=\"training range\")\n",
    "        ax.legend([\"signal\", \"training range\"], loc=\"upper left\")\n",
    "        plt.title(\"Training dataset coverage\")\n",
    "        plt.show()\n",
    "\n",
    "    # Plot each (context, label) window on top of the test series\n",
    "    for original_entry in test_dataset:\n",
    "        s = _to_datetime_index(to_pandas(original_entry))\n",
    "        for test_input, test_label in test_pairs:\n",
    "            ax = s.plot()\n",
    "            highlight_entry(test_input, \"green\", label=\"model input/context\")\n",
    "            highlight_entry(test_label, \"blue\", label=\"prediction target (30 min)\")\n",
    "            ax.legend(\n",
    "                [\"signal\", \"model input/context\", \"prediction target (30 min)\"],\n",
    "                loc=\"upper left\",\n",
    "            )\n",
    "            plt.title(\"Test windows\")\n",
    "            plt.show()\n",
    "\n",
    "############################################\n",
    "# 6. Call the plotting function\n",
    "############################################\n",
    "plot_train_and_test_windows(train_full, test_full, test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DeepAREstimator(\n",
    "    freq=\"5min\",\n",
    "    prediction_length=prediction_length,\n",
    "    trainer_kwargs={\"max_epochs\": 50}\n",
    ")\n",
    "\n",
    "predictor = estimator.train(train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "first_pair = next(iter(test_pairs))\n",
    "second_pair = next(iter(test_pairs))\n",
    "third_pair = next(iter(test_pairs))\n",
    "\n",
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=first_pair,      # pass the TestData as-is\n",
    "    predictor=predictor,\n",
    ")\n",
    "\n",
    "forecasts = list(forecast_it)   # materialize generators\n",
    "labels   = list(ts_it)\n",
    "\n",
    "evaluator = Evaluator(quantiles=(np.arange(20)/20.0)[1:])\n",
    "agg_metrics, item_metrics = evaluator(labels, forecasts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
