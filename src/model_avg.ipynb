{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../3OEC_current_flow.csv')\n",
    "\n",
    "df[\"O2_avg\"] = df[[\"O2_S1\", \"O2_S2\", \"O2_S3\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MARE(prediction_tensor, truth_tensor):\n",
    "    return torch.sum(torch.abs((prediction_tensor - truth_tensor)/truth_tensor))/truth_tensor.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-11 14:00:00\n",
      "2017-07-11 14:00:00 2017-07-12 08:00:00\n",
      "518401\n",
      "2017-07-13 10:59:59.875000\n",
      "2017-07-13 10:59:59.875000 2017-07-14 06:00:00\n",
      "547202\n",
      "2017-07-15 10:00:00\n",
      "2017-07-15 10:00:00 2017-07-16 06:00:00\n",
      "576001\n",
      "2017-07-16 16:00:00\n",
      "2017-07-16 16:00:00 2017-07-17 06:00:00\n",
      "403201\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_time_11 = datetime(2017, 7, 11, 14, 0, 0)\n",
    "end_time_11 = datetime(2017, 7, 12, 8, 0, 0)\n",
    "\n",
    "start_time_13 = datetime(2017, 7, 13, 11, 0, 0)\n",
    "end_time_13 = datetime(2017, 7, 14, 6, 0, 0)\n",
    "\n",
    "start_time_15 = datetime(2017, 7, 15, 10, 0, 0)\n",
    "end_time_15 = datetime(2017, 7, 16, 6, 0, 0)\n",
    "\n",
    "start_time_16 = datetime(2017, 7, 16, 16, 0, 0)\n",
    "end_time_16 = datetime(2017, 7, 17, 6, 0, 0)\n",
    "\n",
    "deployments = {\n",
    "    \"3oec_2017_7_11_12\": {\"start\": start_time_11, \"end\": end_time_11},\n",
    "    \"3oec_2017_7_13_14\": {\"start\": start_time_13, \"end\": end_time_13},\n",
    "    \"3oec_2017_7_15_16\": {\"start\": start_time_15, \"end\": end_time_15},\n",
    "    \"3oec_2017_7_16_17\": {\"start\": start_time_16, \"end\": end_time_16}\n",
    "}\n",
    "\n",
    "date_ranges = []\n",
    "\n",
    "for deployment_name, deployment_info in deployments.items():\n",
    "    start_time = deployment_info[\"start\"]\n",
    "    end_time = deployment_info[\"end\"]\n",
    "    if deployment_name == \"3oec_2017_7_13_14\":\n",
    "        start_time -= timedelta(seconds=0.125)\n",
    "    print(start_time)\n",
    "\n",
    "    # Calculate total seconds and number of measurements\n",
    "    total_seconds = (end_time - start_time).total_seconds() + 0.125\n",
    "    num_measurements = int(total_seconds * 8)\n",
    "\n",
    "    # Create DatetimeIndex for the deployment\n",
    "    date_range = pd.date_range(start=start_time, periods=num_measurements, freq=f'{1000/8}ms')\n",
    "    print(date_range[0], date_range[-1])\n",
    "    print(len(date_range))\n",
    "    date_ranges.append(pd.Series(date_range))\n",
    "\n",
    "# Concatenate all DatetimeIndexes\n",
    "complete_index = pd.concat(date_ranges)\n",
    "\n",
    "# Set the complete index to your DataFrame\n",
    "df.index = complete_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop deployment column and resample\n",
    "df_resampled = df.drop(columns=['deployment', 't', 't_increase', 'Vx', 'Vy', 'Vz', 'P', 'O2_S1', 'O2_S2', 'O2_S3']).resample('5min').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_piece = df_resampled[\"2017-07-11\":\"2017-07-12 06:00:00\"]\n",
    "second_piece = df_resampled[\"2017-07-13 12:00:00\":\"2017-07-14 06:00:00\"]\n",
    "third_piece = df_resampled[\"2017-07-15 12:00:00\":\"2017-07-16 6:00:00\"]\n",
    "fourth_piece = df_resampled[\"2017-07-16 16:00:00\":\"2017-07-17\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, val, test (70-20-10)\n",
    "\n",
    "column_indices = {name: i for i, name in enumerate(first_piece.columns)}\n",
    "n = len(first_piece)\n",
    "train_df1 =first_piece[0:int(n*0.6)]\n",
    "val_df1 = first_piece[int(n*0.6):int(n*0.8)]\n",
    "test_df1 = first_piece[int(n*0.8):]\n",
    "\n",
    "# Normalize the data (each partition separately)\n",
    "train_mean1 = train_df1.mean()\n",
    "train_std1 = train_df1.std()\n",
    "\n",
    "train_df1 = (train_df1 - train_mean1) / train_std1\n",
    "val_df1 = (val_df1 - train_mean1) / train_std1\n",
    "test_df1 = (test_df1 - train_mean1) / train_std1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
